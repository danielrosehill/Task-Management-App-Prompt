# Just A Humble Stack Research Prompt!

*02-Jan-25*

One of the most useful use cases for large language models that I’ve found is their ability to conduct stack research - guiding the way through vast troves of identical products stuffed with often exaggerated marketing claims, bought reviews, and other perils of the evaluation process.  

As what you might perhaps call a long-term tech addict. I love nothing more than discovering a well-engineered tool that brings real value to my life and solves a real problem elegantly. What I don't enjoy? Wading through multiple tools to find that they don't do what I thought they did, are missing a key feature, etc. 

Google search queries are limited to a few words. Because the volumes of those words can be collated as “keywords”, the very mechanism by which search engines operate inadvertently create a powerful enticement for affiliate marketers to litter the web with deceptive and inaccurate material. 

Data shows that large language model prompts do not suffer significant degradation in accuracy until lengths approaching 1000 tokens (and improvement is already apparent). This means that (theoretically at least) large language models present an exciting opportunity for everyone evaluating stack components or standalone tools. 

So in theory, at least, by exploiting what large language models do well, we can write highly detailed and focused stack research prompts that hone the models in on our precise requirements.  If we can figure out a way to get over the training data problem (for example, by using a RAG pipeline to make sure that the data they have is up to date) we can - again, in theory - achieve wonderful things, finding perfect tools almost effortlessly. 

As anyone who has spent time at the grindstone of prompt-writing trying to use LLMs for this purpose knows, however,  the reality is a bit less rosy. 

While models sometimes *do* exhibit flashes of brilliance, pulling off the heroic act of finding the perfect but somewhat obscure tool from a long litany of second-bests that dominated the SERPs, just as often, they fumble around and cause us exasperation, suggesting inappropriate tools or ignoring our instructions. 

Perhaps like others, I've spent time trying to understand the mysteries of this inconsistency, with a view to improving the reliability of my own prompt writing. 

This repository captures a few versions of a prompt that I wrote attempting to find an elusive task management and note and task capturing app. 

As this use case fits within the bloated world of productivity tools, it's a good example, I thought, of a prompt that could in theory streamline the evaluation. 

An LLM that pulled off this task on the first go would be incredibly useful! However, on the first run of this prompt with the latest Gemini model, Obsidian was recommended - a tool that doesn't have an online interface (a recommendation that ignores the first feature!). So although so much of what they can do is cutting edge. LLMs, therefore, are perhaps best understood as promising but rudimentary tools in this particular application.

In this repo:

 I'll jot down some notes on why the iterations were necessary, which models succeeded with the task if any, and what conclusions I drew from the search. 

## Author

Daniel Rosehill  
(public at danielrosehill dot com)

## Licensing

This repository is licensed under CC-BY-4.0 (Attribution 4.0 International) 
[License](https://creativecommons.org/licenses/by/4.0/)

### Summary of the License
The Creative Commons Attribution 4.0 International (CC BY 4.0) license allows others to:
- **Share**: Copy and redistribute the material in any medium or format.
- **Adapt**: Remix, transform, and build upon the material for any purpose, even commercially.

The licensor cannot revoke these freedoms as long as you follow the license terms.

#### License Terms
- **Attribution**: You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.
- **No additional restrictions**: You may not apply legal terms or technological measures that legally restrict others from doing anything the license permits.

For the full legal code, please visit the [Creative Commons website](https://creativecommons.org/licenses/by/4.0/legalcode).